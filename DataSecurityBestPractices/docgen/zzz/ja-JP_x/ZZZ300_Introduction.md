## はじめに

さまざまな産業における大規模言語モデル（LLM）の急速な普及は、高度なデータセキュリティ実践の重要性を浮き彫りにしています。これらのAIシステムが高度化するにつれて、機密情報の漏洩の可能性や厳格なデータ保護規制の遵守に関わる課題など、これまでにないリスクが伴います。本ホワイトペーパーは、これらの新たな脆弱性に対応し、関連リスクを効果的に軽減するために設計された、LLMデータセキュリティの包括的なベストプラクティスを示しています。

このイニシアチブは、OWASP Top 10 for LLM AI Applications 2025リストを補完し、安全で責任あるAIエコシステムへの継続的なコミットメントを強化します。本論文の目的は、LLM（大規模言語モデル）の文脈におけるデータ保護とそのベストプラクティスに関する情報提供、教育、洞察を提供することです。コミュニティによって、そしてコミュニティのために作成された追加のコンテンツを通じて、新たな視点をもたらします。本プロジェクトで作成された他の有用な文書、例えばLLM Cybersecurity and Governance Checklist、LLM GenAI Security Center of Excellence、The Guide for Preparing and Responding to Deepfake Events、The AI Security Solution Landscape Guide、GenAI Red Teaming Guideなどを補完します。データ収集方法論チームによって執筆・発表された本ホワイトペーパーは、厳密かつ体系的なデータ収集と分析手法をもたらし、私たちの推奨事項が実践的であり、かつ世界的なセキュリティフレームワークと整合していることを保証します。

### なぜデータセキュリティがLLMにとって重要なのか

データセキュリティは、使用および開発に伴う重大なリスクと脆弱性のため、大規模言語モデル（LLM）にとって非常に重要です。データはすべてのLLMの「生命線」であり、その保護を確実にするためには以下が含まれます：

#### 機密情報の保護

LLMは、しばしば機密情報やセンシティブな情報を含む可能性のある膨大なデータセットで訓練されます。データのセキュリティを確保することは次の目的において重要です：
- 個人情報、金融情報、または独自データへの不正アクセスを防止する
- ユーザーのプライバシーと信頼を維持する
- データ保護規則に準拠する
  ​
  強力な暗号化、アクセス制御、および匿名化技術を実装することは、LLMのトレーニングおよび運用で使用される機密データを保護するのに役立ちます。
  ​
#### データの整合性と信頼性の確保

LLMで使用されるデータの整合性と信頼性の維持は以下のために不可欠です:
- 正確で信頼できる出力を生成すること
- 誤情報や偏った内容の拡散を防止すること
- モデルの性能がその意図された目的に適合していることを保証すること
  ​
  データ検証プロセスの実装と継続的な監視は、データの完全性を損なう可能性のある脅威を検出し対応するのに役立ちます。
  ​
#### プライバシー問題への対応

LLMは人間のようなテキストを処理・生成する能力があるため、重大なプライバシー問題を引き起こします。以下のために堅牢なデータセキュリティ対策が必要です：
- ユーザーの入力を保護し、個人情報の不正な開示を防止する
- GDPRのようなプライバシー規制の遵守を確保する
- AI搭載アプリケーションにおけるユーザーの信頼を維持する
  ​
  差分プライバシーやフェデレーテッドラーニングなどのプライバシー強化技術を採用することで、個人のプライバシーを保護しながら、LLMが幅広いデータからの洞察を学習できるようになります。
  ​
#### 新たに浮上する脅威の軽減

LLMがますます普及するにつれて、新たなセキュリティ課題が生じます：
- AI生成コンテンツを使用した高度なフィッシング攻撃
- 大規模なオンライン情報の操作
- LLMの能力を活用した自動化されたサイバー攻撃
- 誤情報
- 無制限の消費
  ​
  堅牢なデータセキュリティは、LLMの責任ある開発と展開を保証するために不可欠です。包括的なセキュリティ戦略を実施することで、組織はLLMの力を活用しつつ、機密情報を保護しユーザーの信頼を維持することができます。高度なセキュリティ対策を導入し、進化する脅威に対して警戒を続けることは、LLMとそのユーザーを守るために極めて重要です。
  ​
### 従来型データセキュリティとLLM特化型データセキュリティの比較

![fig1](images/fig1.png)
ソース：[Rob van der Veer (Software Improvement Group)](https://www.linkedin.com/posts/robvanderveer_ai-aisecurity-activity-7274736168255074304-g9yq?utm_source=share&utm_medium=member_desktop)
##### 図1：影響、資産、および脅威

#### 従来のデータセキュリティ対策

暗号化、アクセス制御、データマスキング、ネットワークセキュリティなどの従来のセキュリティ手法は、大規模言語モデル（LLM）のデータ保護の基盤となる層を構成しています。これらの長年にわたる実績のある方法は、基本的な保護を保証し、あらゆる堅牢なシステムでのコンプライアンス維持に寄与します。例えば、保存時の暗号化（AES-256など）や通信時の暗号化（TLS 1.3など）は、データの保存および通信中の安全を確保し、ロールベースアクセス制御（RBAC）や多要素認証（MFA）は不正なアクセスを制限します。データマスキングや匿名化技術は偶発的な情報漏洩のリスクを軽減し、詳細な監査とログ記録はトラブルシューティングやコンプライアンス報告のための監査証跡を提供します。ファイアウォール、VPN、侵入検知システムはさらにネットワーク境界を強化し、正当なトラフィックのみが通過できるようにします。これらの制御は総合的に、LLMに対して追加のより専門的なプロトコルを適用するための基盤を形成します。

#### LLM特有のセキュリティ適応

これらの従来の必要な対策は、AIライフサイクル全体で発生する固有の課題に対応するために強化されなければなりません。バージョン管理、ロールバック機能、企業標準の遵守を包含するモデルライフサイクル管理およびガバナンスフレームワークは、トレーニングデータの出所を監視し、追跡可能性を維持するのに役立ちます。安全な開発プロセスと検証されたサプライチェーンは、外部ライブラリやカスタムスクリプトによってもたらされる脆弱性を最小限に抑えます。敵対的テスト、モデル反転分析、ペネトレーション演習などの脅威評価は、侵害につながる前にシステムの弱点を明らかにします。日常の運用においては、継続的な監視とリアルタイムの異常検知を支えるインシデント対応プロトコルが、侵害やデータ漏洩事案の迅速な封じ込めに不可欠です。これらの制御はまた、データ所在規則の順守や意図しないバイアスの軽減を含む、より広範な法的および倫理的考慮事項とも交差します。

#### 潜在的なリスクと影響

OWASP Top 10 for LLM GenAI アプリケーション 2025リストは、専門家のグループによって編成およびキュレーションされており、大規模言語モデルに関連する主要なセキュリティリスクと潜在的な影響を提示しています。そのうちの10のうち6つはデータセキュリティに特化しています：

リスク:[LLM01:2025 Prompt Injection](https://genai.owasp.org/llmrisk/llm01-prompt-injection/)
説明：悪意のある攻撃者は、プロンプトを操作してモデルの動作を変更し、許可されていないコンテンツの生成や意図しない動作の実行を引き起こす可能性があります。
統計：研究によると、Retrieval Augmented Generation（RAG）などの高度な防御策でさえ、これらの脆弱性を完全に防ぐことはできません。

リスク:[LLM02:2025 Sensitive Information Disclosure](https://genai.owasp.org/llmrisk/llm022025-sensitive-information-disclosure/)
説明：LLMは、その出力を通じて個人を特定できる情報（PII）、独自のアルゴリズム、または機密のビジネスデータを漏洩するリスクがあります。例えば、不十分にサニタイズされたデータは意図しない情報漏洩につながる可能性があります。
統計：研究によると、Retrieval Augmented Generation（RAG）のような高度な防御策でさえ、これらの脆弱性を完全に防ぐことはできません。

リスク:[LLM04:2025 Data and Model Poisoning](https://genai.owasp.org/llmrisk/llm042025-data-and-model-poisoning/)
説明：攻撃者はトレーニングデータやモデル自体を破損させ、誤解を招く出力を生成させたり、モデルの完全性を損なう可能性があります。
統計：敵対的事例は、防御機構があってもモデルの出力に影響を与える成功率が35%であることが示されています。

リスク:[LLM03:2025 Supply Chain Vulnerabilities](https://genai.owasp.org/llmrisk/llm032025-supply-chain/)
説明：安全でない依存関係やライブラリは、LLMの展開にリスクをもたらす可能性があります。攻撃者はこれらの外部ソースを侵害して、モデルやデータにアクセスすることができます。
統計情報：「Proof Pudding」攻撃（CVE-2019-20634）は、公開されたトレーニングデータがモデル抽出を促進し、重大なプライバシーおよびセキュリティ違反を引き起こしたことを示しました。

リスク:[LLM05:2025 Improper Output Handling](https://genai.owasp.org/llmrisk/llm052025-improper-output-handling/)
説明：LLMは、その出力が適切に検証および管理されない場合、有害なコンテンツを意図せず生成したり、機密情報を漏洩したりする可能性があります。
統計：最近の侵害事例では、フィルタリングされていないLLMの応答が、分析されたケースの12％でデータ漏洩の原因となっていることが明らかになりました。

リスク:[LLM07:2025 System Prompt Leakage](https://genai.owasp.org/llmrisk/llm072025-system-prompt-leakage/)
説明：攻撃者がシステムプロンプトにアクセスすると、モデルの構成に関する詳細を抽出し、それを利用してさらなる攻撃を仕掛ける可能性があります。
統計：敵対的事例は、防御機構があるにもかかわらず、モデルの出力に影響を与える成功率が35%であることが示されています。

#### より広い影響

大規模言語モデル（LLM）に関連するデータセキュリティリスクは複数の側面にわたり、その重要な広範な影響には以下が含まれます：

1.  誤情報と操作：LLMは、誤ったまたは誤解を招く情報を生成・拡散するために悪用される可能性があり、その結果として以下が生じる可能性があります。
- ソーシャルエンジニアリング攻撃
- AIシステムに対する信頼の侵食
- 潜在的な社会的影響
- リンクトラップ
  ​
2. AI生成情報への過度な依存：適切な検証なしにLLMの出力を信頼すると、以下の結果を招く可能性があります：
- セキュリティ侵害
- 法的問題
- 評判の損害
  ​
3. 倫理的懸念：LLMの使用は次の点に関する疑問を提起します：
- AIの意思決定におけるバイアス
- 公平性と差別
- AI生成コンテンツに対する責任
- 透明性
  ​
  これらのリスクを軽減するためには、組織が強固なセキュリティ対策を実施することが必要であり、その中にはデータの管理も含まれます。
  匿名化、入力検証、出力のサニタイズ、LLMシステムの継続的監視など。
  ​
  さらに、倫理的ガイドラインを策定し、重要な意思決定プロセスにおいて人間の監督を維持することは、責任あるAIの展開にとって極めて重要です。
  ​
  この取り組みは、これらのリスクの軽減および安全な開発と展開の実践の確立に関する詳細なガイダンスを提供する、より広範なOWASP LLMおよびジェネレーティブAIセキュリティプロジェクトと密接に連携しています。OWASP AIセキュリティおよびプライバシーガイド（Ref.1）は、データプライバシー、倫理的影響、および責任あるAI開発に対処する貴重な包括的視点を提供します。OWASP AIエクスチェンジ（Ref.2）は、情報の中央リポジトリとして機能し、この分野内での協力を促進します。
  ​
  [Ref.1 - OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
  [Ref.2 - OWASP AI Exchange](https://owaspai.org/)
  ​
  これらの取り組みは直接的にLLMのセキュリティに対処していますが、確立されたOWASPプロジェクトは貴重で移転可能な知見を提供します。OWASPアプリケーションセキュリティ検証標準（ASVS）（参照3）は、LLMを統合するアプリケーションのセキュリティを検証するためのフレームワークを提供し、OWASPテスティングガイドおよびウェブセキュリティテスティングガイド（WSTG）（参照4）は、LLMベースのシステムに適用可能な方法論を提供します。
  ​
  [Ref.3 - OWASP Application Security Verification Standard (ASVS)](https://owasp.org/www-project-application-security-verification-standard/)
  [Ref.4 - OWASP Testing Guide and Web Security Testing Guide (WSTG)](https://owasp.org/www-project-web-security-testing-guide/)
  ​
  ​
  OWASPチートシートシリーズ（参照5）は特定のセキュリティ技術に関する簡潔なガイダンスを提供しており、OWASP脅威モデリングプロジェクト（参照6）とThreat Dragonツール（参照7）は、LLM展開における効果的な脅威分析を可能にします。
  ​
  [Ref.5 - OWASP Cheat Sheet Series](https://cheatsheetseries.owasp.org/)
  [Ref.6 - OWASP Threat Modeling Project](https://owasp.org/www-project-threat-model/)
  [Ref.7 - Threat Dragon tool](https://owasp.org/www-project-threat-dragon/)
  ​
  LLMの依存関係におけるサプライチェーンセキュリティは、OWASP Dependency-CheckおよびDependency-Track（参考文献8）を使用して管理できます。さらに、OWASP Software Assurance Maturity Model（SAMM）（参考文献9）を適用することで、LLMのライフサイクルを包含する堅牢なソフトウェアセキュリティプログラムの開発が促進され、OWASP DevSecOps Maturity Model（DSOMM）（参考文献10）は、LLMインフラストラクチャおよびデータ管理の運用面へのセキュリティ統合を支援します。
  ​
  [Ref.8 - OWASP Dependency-Check and Dependency-Track](https://owasp.org/www-project-dependency-track/)
  [Ref.9 - OWASP Software Assurance Maturity Model (SAMM)](https://owasp.org/www-project-samm/)
  [Ref.10 - OWASP DevSecOps Maturity Model (DSOMM)](https://owasp.org/www-project-devsecops-maturity-model/)
  ​
  OWASPコードレビュ―ガイド（参考文献11）の原則は、LLMと連携するコードを精査する上で不可欠であり、OWASPセキュリティ知識フレームワーク（SKF）（参考文献12）は、さまざまなLLMセキュリティ領域に適用可能な幅広いセキュリティ知識の基盤を提供します。
  ​
  [Ref.11 - OWASP Code Review Guide](https://owasp.org/www-project-code-review-guide/)
  [Ref.12 - OWASP Security Knowledge Framework (SKF)](https://www.securityknowledgeframework.org/)
  ​
  この包括的なOWASPリソースのセットは、効果的なLLMデータセキュリティのベストプラクティスを確立し実施するために不可欠です。
  ​
  LLM 2025のためのOWASPトップ10リストの詳細については、以下をご覧ください：[https://genai.owasp.org/llm-top-10/](https://genai.owasp.org/llm-top-10/)

